#!/usr/bin/env python3
"""
æµ‹è¯•ç®€åŒ–ç‰ˆ BM25 æœç´¢å¼•æ“Ž
"""
import json
from pathlib import Path

def test_simple_search():
    """æµ‹è¯•ç®€åŒ–ç‰ˆæœç´¢å¼•æ“Ž"""
    
    print("=" * 60)
    print("æµ‹è¯•ç®€åŒ–ç‰ˆ BM25 æœç´¢å¼•æ“Ž")
    print("=" * 60)
    
    # 1. å¯¼å…¥æ¨¡å—
    print("\n1. å¯¼å…¥æœç´¢å¼•æ“Žæ¨¡å—...")
    try:
        from search_engine_simple import SimplePaperSearchEngine, simple_search_papers
        print("   âœ… å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"   âŒ å¯¼å…¥å¤±è´¥: {e}")
        print("\nè¯·å®‰è£… tantivy:")
        print("   pip install tantivy")
        return False
    
    # 2. åˆ›å»ºæµ‹è¯•æ•°æ®
    print("\n2. åˆ›å»ºæµ‹è¯•æ•°æ®...")
    test_papers = [
        {
            "id": "2301.00001",
            "arxiv_id": "2301.00001",
            "title": "Attention Is All You Need: The Transformer Architecture",
            "abstract": "We propose a new simple network architecture, the Transformer, based solely on attention mechanisms.",
            "authors": ["Ashish Vaswani", "Noam Shazeer"],
            "categories": ["cs.AI", "cs.LG"],
            "published_date": "2023-01-01"
        },
        {
            "id": "2301.00002",
            "arxiv_id": "2301.00002",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "abstract": "We introduce BERT, which stands for Bidirectional Encoder Representations from Transformers.",
            "authors": ["Jacob Devlin", "Ming-Wei Chang"],
            "categories": ["cs.CL", "cs.AI"],
            "published_date": "2023-01-02"
        },
        {
            "id": "2301.00003",
            "arxiv_id": "2301.00003",
            "title": "Large Language Models: GPT-4 Technical Report",
            "abstract": "We report the development of GPT-4, a large-scale multimodal model.",
            "authors": ["OpenAI Team"],
            "categories": ["cs.AI"],
            "published_date": "2023-01-03"
        },
        {
            "id": "2301.00004",
            "arxiv_id": "2301.00004",
            "title": "Vision Transformers for Image Recognition",
            "abstract": "We show that a pure transformer applied directly to image patches can perform very well on image classification.",
            "authors": ["Alexey Dosovitskiy"],
            "categories": ["cs.CV", "cs.LG"],
            "published_date": "2023-01-04"
        }
    ]
    
    print(f"   åˆ›å»ºäº† {len(test_papers)} ç¯‡æµ‹è¯•è®ºæ–‡")
    
    # 3. åˆå§‹åŒ–æœç´¢å¼•æ“Ž
    print("\n3. åˆå§‹åŒ–æœç´¢å¼•æ“Ž...")
    try:
        engine = SimplePaperSearchEngine(index_path="./test_simple_index")
        print("   âœ… åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"   âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    # 4. æž„å»ºç´¢å¼•
    print("\n4. æž„å»ºç´¢å¼•...")
    try:
        engine.build_index(test_papers)
        stats = engine.get_index_stats()
        print(f"   âœ… ç´¢å¼•æž„å»ºæˆåŠŸ")
        print(f"   ç´¢å¼•çŠ¶æ€: {stats}")
    except Exception as e:
        print(f"   âŒ ç´¢å¼•æž„å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 5. æµ‹è¯•æœç´¢
    print("\n5. æµ‹è¯•æœç´¢...")
    
    test_queries = [
        ("transformer", 3),
        ("LLM", 2),
        ("GPT", 1),
        ("vision", 1),
    ]
    
    all_passed = True
    for query, expected_min in test_queries:
        print(f"\n   æŸ¥è¯¢: '{query}'")
        try:
            results = engine.search(query, max_results=10)
            
            if results:
                print(f"   âœ… æ‰¾åˆ° {len(results)} ä¸ªç»“æžœ")
                for i, result in enumerate(results[:2], 1):
                    title = result['title'][:60] + "..." if len(result['title']) > 60 else result['title']
                    print(f"      {i}. {title}")
                    print(f"         Score: {result['search_score']:.4f}")
                
                if len(results) < expected_min:
                    print(f"   âš ï¸ é¢„æœŸè‡³å°‘ {expected_min} ä¸ªç»“æžœï¼Œå®žé™… {len(results)} ä¸ª")
            else:
                print(f"   âš ï¸ æœªæ‰¾åˆ°ç»“æžœ")
                all_passed = False
                
        except Exception as e:
            print(f"   âŒ æœç´¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            all_passed = False
    
    # 6. æµ‹è¯•ä¾¿æ·å‡½æ•°
    print("\n6. æµ‹è¯•ä¾¿æ·å‡½æ•°...")
    try:
        results = simple_search_papers(
            query="transformer",
            papers=test_papers,
            search_engine=engine
        )
        print(f"   âœ… simple_search_papers è¿”å›ž {len(results)} ä¸ªç»“æžœ")
    except Exception as e:
        print(f"   âŒ ä¾¿æ·å‡½æ•°å¤±è´¥: {e}")
        all_passed = False
    
    # 7. æ¸…ç†
    print("\n7. æ¸…ç†æµ‹è¯•ç´¢å¼•...")
    try:
        engine.clear_index()
        print("   âœ… æ¸…ç†å®Œæˆ")
    except Exception as e:
        print(f"   âš ï¸ æ¸…ç†å¤±è´¥: {e}")
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    if all_passed:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("=" * 60)
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        print("=" * 60)
        return False


def test_with_real_data():
    """ä½¿ç”¨çœŸå®žæ•°æ®æµ‹è¯•"""
    
    print("\n" + "=" * 60)
    print("ä½¿ç”¨çœŸå®žè®ºæ–‡æ•°æ®æµ‹è¯•")
    print("=" * 60)
    
    # æŸ¥æ‰¾è®ºæ–‡æ•°æ®æ–‡ä»¶
    data_dir = Path("papers_data")
    if not data_dir.exists():
        print("âŒ papers_data ç›®å½•ä¸å­˜åœ¨")
        return False
    
    json_files = list(data_dir.glob("papers_*.json"))
    if not json_files:
        print("âŒ æœªæ‰¾åˆ°è®ºæ–‡æ•°æ®æ–‡ä»¶")
        return False
    
    json_file = sorted(json_files)[-1]
    print(f"\nä½¿ç”¨æ–‡ä»¶: {json_file}")
    
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if isinstance(data, list):
        papers = data
    elif isinstance(data, dict) and 'papers' in data:
        papers = data['papers']
    else:
        print("âŒ æ— æ³•è§£æžè®ºæ–‡æ•°æ®")
        return False
    
    print(f"åŠ è½½äº† {len(papers)} ç¯‡è®ºæ–‡")
    
    # å¯¼å…¥å¹¶æµ‹è¯•
    try:
        from search_engine_simple import simple_search_papers
        
        print("\næµ‹è¯•æœç´¢...")
        results = simple_search_papers(
            query="transformer",
            papers=papers[:100]  # åªç”¨å‰100ç¯‡æµ‹è¯•
        )
        
        print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªç»“æžœ")
        for i, paper in enumerate(results[:3], 1):
            print(f"{i}. {paper['title'][:70]}...")
            if 'search_score' in paper:
                print(f"   Score: {paper['search_score']:.4f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    # åŸºæœ¬æµ‹è¯•
    success = test_simple_search()
    
    # å¦‚æžœåŸºæœ¬æµ‹è¯•é€šè¿‡ï¼Œå°è¯•çœŸå®žæ•°æ®
    if success:
        test_with_real_data()
    
    print("\nðŸŽ‰ æµ‹è¯•å®Œæˆï¼")
