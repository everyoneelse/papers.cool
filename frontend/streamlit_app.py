"""
TEST PAGE
"""

import streamlit as st
from datetime import datetime, timedelta
import pandas as pd
from typing import List, Dict, Optional
import json
import os
from pathlib import Path
import io

import sys
sys.path.append("/home/hhy/project/paper-agent/papers.cool-main/backend/utils")
# å¯¼å…¥ BM25 æœç´¢å¼•æ“
try:
    from search_engine import PaperSearchEngine, search_papers_bm25
    SEARCH_ENGINE_AVAILABLE = True
except ImportError:
    SEARCH_ENGINE_AVAILABLE = False
    st.warning("âš ï¸ Tantivy æœç´¢å¼•æ“ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€å•æœç´¢æ¨¡å¼ã€‚è¯·å®‰è£…: pip install tantivy")


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="TEST PAGE",
    page_icon="ğŸ“",
)

# æ•°æ®ç›®å½• - å‡è®¾è®ºæ–‡æ•°æ®æŒ‰æ—¥æœŸå­˜å‚¨ä¸ºJSONæ–‡ä»¶
DATA_DIR = os.getenv("DATA_DIR", "/home/hhy/project/paper-agent/papers-agent/papers_data")
#DATA_DIR = os.getenv("DATA_DIR", "./papers_data")

# åç«¯ API åœ°å€
API_BASE_URL = st.secrets.get("API_BASE_URL", "http://localhost:8000")

# åˆå§‹åŒ– session state
if "starred_papers" not in st.session_state:
    st.session_state.starred_papers = set()
if "viewed_papers" not in st.session_state:
    st.session_state.viewed_papers = set()
if "selected_categories" not in st.session_state:
    st.session_state.selected_categories = ["cs.AI", "cs.CL", "cs.LG"]

if "search_engine" not in st.session_state and SEARCH_ENGINE_AVAILABLE:
    st.session_state.search_engine = None

if "search_mode" not in st.session_state:
    st.session_state.search_mode = "bm25" if SEARCH_ENGINE_AVAILABLE else "simple"


# ArXiv åˆ†ç±»å®šä¹‰
ARXIV_CATEGORIES = {
    "Artificial Intelligence (cs.AI)": "cs.AI",
    "Computation and Language (cs.CL)": "cs.CL",
    "Computer Vision (cs.CV)": "cs.CV",
    "Machine Learning (cs.LG)": "cs.LG",
    "Neural and Evolutionary Computing (cs.NE)": "cs.NE",
    "Computational Complexity (cs.CC)": "cs.CC",
    "Statistics - Machine Learning (stat.ML)": "stat.ML",
}

# Pills èƒ¶å›Šå¼é¢œè‰²å®šä¹‰ - ä½¿ç”¨æŸ”å’Œçš„é…è‰²æ–¹æ¡ˆ
CATEGORY_COLORS = {
    "cs.AI": {"bg": "#FFE5E5", "border": "#FF6B6B", "text": "#CC0000"},           # æŸ”å’Œçº¢
    "cs.CL": {"bg": "#E0F7F7", "border": "#4ECDC4", "text": "#008B8B"},           # æŸ”å’Œé’
    "cs.CV": {"bg": "#E3F2FD", "border": "#45B7D1", "text": "#1565C0"},           # æŸ”å’Œè“
    "cs.LG": {"bg": "#E8F5E9", "border": "#96CEB4", "text": "#2E7D32"},           # æŸ”å’Œç»¿
    "cs.NE": {"bg": "#FFF9E6", "border": "#FFEAA7", "text": "#F57F17"},           # æŸ”å’Œé»„
    "cs.CC": {"bg": "#F5F5F5", "border": "#DFE6E9", "text": "#616161"},           # æŸ”å’Œç°
    "stat.ML": {"bg": "#F3E5F5", "border": "#A29BFE", "text": "#6A1B9A"},         # æŸ”å’Œç´«
}


def load_papers_from_json(date_str: str, selected_categories: List[str] = None) -> List[Dict]:
    """
    ä»JSONæ–‡ä»¶åŠ è½½æŒ‡å®šæ—¥æœŸçš„è®ºæ–‡æ•°æ®
    æ”¯æŒæ–°çš„æŒ‰ç±»åˆ«ç»„ç»‡æ ¼å¼å’Œæ—§çš„æ€»æ–‡ä»¶æ ¼å¼:
    1. æ–°æ ¼å¼: papers_data/cs.AI/papers_YYYY-MM-DD_100percent.json (æŒ‰ç±»åˆ«æ–‡ä»¶å¤¹)
    2. æ—§æ ¼å¼: papers_data/papers_YYYY-MM-DD_100percent.json (æ€»æ–‡ä»¶)
    """
    data_path = Path(DATA_DIR)
    all_papers = []

    # é¦–å…ˆå°è¯•æ–°çš„æŒ‰ç±»åˆ«ç»„ç»‡æ ¼å¼
    category_files_found = False

    # ç¡®å®šè¦åŠ è½½çš„ç±»åˆ«
    categories_to_load = selected_categories if selected_categories else ARXIV_CATEGORIES.values()

    for category in categories_to_load:
        category_dir = data_path / category
        json_file = category_dir / f"papers_{date_str}_100percent.json"

        if json_file.exists():
            category_files_found = True
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                    # å¤„ç†æ•°æ®æ ¼å¼
                    if isinstance(data, dict) and "papers" in data:
                        papers = data["papers"]
                        all_papers.extend(papers)
                    else:
                        continue

            except Exception as e:
                continue

    # å¦‚æœæ‰¾åˆ°äº†ç±»åˆ«æ–‡ä»¶ï¼Œç›´æ¥è¿”å›åˆå¹¶çš„ç»“æœ
    if category_files_found and all_papers:
        # å»é‡ï¼ˆæŒ‰ arxiv_idï¼‰
        unique_papers = {}
        for paper in all_papers:
            arxiv_id = paper.get("arxiv_id", paper.get("id", ""))
            if arxiv_id and arxiv_id not in unique_papers:
                unique_papers[arxiv_id] = paper

        result_papers = list(unique_papers.values())
        return result_papers

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç±»åˆ«æ–‡ä»¶ï¼Œå°è¯•æ—§çš„æ€»æ–‡ä»¶æ ¼å¼
    legacy_files = [
        data_path / f"papers_{date_str}_100percent.json",
        data_path / f"papers_{date_str}.json",
    ]

    for json_file in legacy_files:
        if json_file.exists():
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                    # å¤„ç†ä¸åŒçš„æ•°æ®æ ¼å¼
                    if isinstance(data, list):
                        # ç›´æ¥æ˜¯è®ºæ–‡åˆ—è¡¨
                        all_papers = data
                    elif isinstance(data, dict):
                        # åŒ…å« metadata çš„æ ¼å¼
                        if "papers" in data:
                            all_papers = data["papers"]
                        else:
                            # å¯èƒ½æ˜¯å•ä¸ªè®ºæ–‡å¯¹è±¡ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
                            all_papers = [data]
                    else:
                        st.warning(f"Unexpected data format in {json_file}")
                        continue
                        
                    st.success(f"âœ… Loaded {len(all_papers)} papers from legacy file {json_file}")
                    return all_papers

            except json.JSONDecodeError as e:
                st.error(f"Invalid JSON in {json_file}: {e}")
                continue
            except Exception as e:
                st.error(f"Error loading papers from {json_file}: {e}")
                continue
    
    # æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡ä»¶
    return []


def filter_papers_by_categories(papers: List[Dict], categories: List[str]) -> List[Dict]:
    """æ ¹æ®é€‰æ‹©çš„åˆ†ç±»è¿‡æ»¤è®ºæ–‡"""
    if not categories:
        return papers
    
    # è½¬æ¢åˆ†ç±»åç§°ä¸ºä»£ç 
    category_codes = [ARXIV_CATEGORIES.get(cat, cat) for cat in categories]
    
    filtered = []
    for paper in papers:
        paper_categories = paper.get("categories", [])
        if isinstance(paper_categories, str):
            paper_categories = [paper_categories]
        
        # æ£€æŸ¥è®ºæ–‡æ˜¯å¦å±äºä»»ä¸€é€‰ä¸­çš„åˆ†ç±»
        if any(cat in paper_categories for cat in category_codes):
            filtered.append(paper)
    
    return filtered


def search_papers_simple(query: str, papers: List[Dict], categories: Optional[List[str]] = None) -> List[Dict]:
    """
    åœ¨è®ºæ–‡ä¸­æœç´¢ï¼ˆæœç´¢æ ‡é¢˜å’Œæ‘˜è¦ï¼‰
    ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…å®ç°

    Args:
        query: æœç´¢å…³é”®è¯
        papers: è®ºæ–‡åˆ—è¡¨
        categories: åˆ†ç±»è¿‡æ»¤åˆ—è¡¨

    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    if not query:
        return papers

    query_lower = query.lower()
    results = []

    for paper in papers:
        title = paper.get("title", "").lower()
        abstract = paper.get("abstract", "").lower()

        # ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…
        if query_lower in title or query_lower in abstract:
            # åº”ç”¨åˆ†ç±»è¿‡æ»¤ï¼ˆå¦‚æœæŒ‡å®šäº†åˆ†ç±»ï¼‰
            if categories:
                paper_categories = paper.get("categories", [])
                if isinstance(paper_categories, str):
                    paper_categories = [paper_categories]

                if not any(cat in paper_categories for cat in categories):
                    continue

            results.append(paper)

    return results


def search_papers(query: str, papers: List[Dict], categories: Optional[List[str]] = None) -> List[Dict]:
    """
    æœç´¢è®ºæ–‡ - æ™ºèƒ½é€‰æ‹©æœç´¢æ–¹å¼
    
    Args:
        query: æœç´¢å…³é”®è¯
        papers: è®ºæ–‡åˆ—è¡¨
        categories: åˆ†ç±»è¿‡æ»¤
        
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    if not query or not query.strip():
        return papers
    
    # å¦‚æœ BM25 æœç´¢å¼•æ“å¯ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨
    if SEARCH_ENGINE_AVAILABLE and st.session_state.search_mode == "bm25":
        try:
            # åˆå§‹åŒ–æˆ–è·å–æœç´¢å¼•æ“
            if st.session_state.search_engine is None:
                st.session_state.search_engine = PaperSearchEngine()
            
            # ä½¿ç”¨ BM25 æœç´¢
            results = search_papers_bm25(
                query=query,
                papers=papers,
                categories=categories,
                search_engine=st.session_state.search_engine,
                rebuild_index=True  # æ¯æ¬¡éƒ½é‡å»ºç´¢å¼•ï¼Œç¡®ä¿åªæœç´¢å½“å‰è®ºæ–‡
            )
            
            return results
            
        except Exception as e:
            st.warning(f"âš ï¸ BM25 æœç´¢å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æœç´¢: {e}")
            return search_papers_simple(query, papers, categories)
    else:
        # ä½¿ç”¨ç®€å•æœç´¢
        return search_papers_simple(query, papers, categories)


def render_category_pills(categories: List[str]):
    """æ¸²æŸ“ Pills èƒ¶å›Šå¼åˆ†ç±»æ ‡ç­¾ - ä½¿ç”¨StreamlitåŸç”Ÿç»„ä»¶"""

    # åˆ›å»ºèƒ¶å›ŠHTML
    pills_html = ""
    for cat in categories:
        colors = CATEGORY_COLORS.get(cat, {"bg": "#F0F0F0", "border": "#BDBDBD", "text": "#424242"})
        pills_html += f'<span style="background-color:{colors["bg"]};color:{colors["text"]};border:2px solid {colors["border"]};padding:6px 12px;border-radius:15px;font-size:12px;font-weight:500;margin:0 4px 4px 0;display:inline-block;">ğŸ”– {cat}</span>'

    st.markdown(f'<div style="margin:10px 0;">{pills_html}</div>', unsafe_allow_html=True)

def papers_to_csv(papers: List[Dict]) -> str:
    """
    å°†è®ºæ–‡åˆ—è¡¨è½¬æ¢ä¸ºCSVå­—ç¬¦ä¸²

    Args:
        papers: è®ºæ–‡åˆ—è¡¨

    Returns:
        CSVæ ¼å¼çš„å­—ç¬¦ä¸²
    """
    if not papers:
        return ""

    # å®šä¹‰CSVåˆ—
    columns = ['title', 'authors', 'categories', 'published_date', 'abstract', 'url', 'pdf_url']

    # åˆ›å»ºæ•°æ®è¡Œ
    data = []
    for paper in papers:
        row = {
            'title': paper.get('title', ''),
            'authors': ', '.join(paper.get('authors', [])) if isinstance(paper.get('authors'), list) else paper.get('authors', ''),
            'categories': ', '.join(paper.get('categories', [])) if isinstance(paper.get('categories'), list) else paper.get('categories', ''),
            'published_date': paper.get('published_date', ''),
            'abstract': paper.get('abstract', ''),
            'url': paper.get('url', ''),
            'pdf_url': paper.get('pdf_url', '')
        }
        data.append(row)

    # è½¬æ¢ä¸ºDataFrameç„¶åå¯¼å‡ºä¸ºCSV
    df = pd.DataFrame(data, columns=columns)
    return df.to_csv(index=False)


def render_paper_card(paper: Dict):

    """æ¸²æŸ“å•ä¸ªè®ºæ–‡å¡ç‰‡"""

    # è®ºæ–‡å®¹å™¨
    with st.container():
        # æ ‡é¢˜
        title = paper.get("title", "Untitled")
        url = paper.get("url", "") or paper.get("pdf_url", "")
        
        if url:
            st.markdown(f"### [{title}]({url})")
        else:
            st.markdown(f"### {title}")

        # ä½œè€…
        authors = paper.get("authors", [])
        if authors:
            if isinstance(authors, list):
                if len(authors) > 5:
                    author_str = ", ".join(authors[:5]) + " et al."
                else:
                    author_str = ", ".join(authors)
            else:
                author_str = str(authors)
            st.markdown(f"**ğŸ‘¥ Authors:** {author_str}")
        
        # åˆ†ç±»å’Œå‘å¸ƒæ—¥æœŸ
        col1, col2 = st.columns(2)
        with col1:
            categories = paper.get("categories", [])
            if categories:
                if isinstance(categories, list):
                    categories_str = ", ".join(categories[:3])
                else:
                    categories_str = str(categories)
                st.caption(f"ğŸ·ï¸ Categories: {categories_str}")        
        with col2:
            pub_date = paper.get("published_date")
            if pub_date:
                st.caption(f"ğŸ“… Published: {pub_date}")
        
        # æ‘˜è¦
        abstract = paper.get("abstract", "")
        if abstract:
            st.markdown("#### ğŸ“„ Abstract")
            st.write(abstract)

        # é“¾æ¥æŒ‰é’®
        col1, _ = st.columns([1, 4])
        
        with col1:
            pdf_url = paper.get("pdf_url", "")
            if pdf_url:
                st.link_button("ğŸ“„ PDF", pdf_url)
        
             
        # åˆ†å‰²çº¿
        st.divider()



        # åˆ†å‰²çº¿
        st.divider()

def main():
    """ä¸»åº”ç”¨"""
    
    # è‡ªå®šä¹‰ CSS
    st.markdown("""
    <style>
    div[data-testid="stExpander"] {
        border: 1px solid #ddd;
        border-radius: 5px;
        padding: 10px;
        margin: 10px 0;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # ä¾§è¾¹æ  - ArXiv åˆ†ç±»é€‰æ‹©
    with st.sidebar:
        st.title("ğŸ“š Cool Papers")
        st.caption("Simplified Interface")
        
        st.markdown("---")
        
        # ArXiv åˆ†ç±»é€‰æ‹©
        st.subheader("ğŸ”¬ arXiv Categories")
        st.caption("Select your interested categories")
        
        selected_cats = []
        for cat_name, cat_code in ARXIV_CATEGORIES.items():
            is_selected = cat_code in st.session_state.selected_categories
            if st.checkbox(cat_name, value=is_selected, key=f"cat_{cat_code}"):
                selected_cats.append(cat_code)
        
        st.session_state.selected_categories = selected_cats
        
        st.markdown("---")
        
        # æ˜¾ç¤ºé€‰ä¸­çš„åˆ†ç±»æ•°é‡
        st.metric("ğŸ“‚ Selected Categories", len(st.session_state.selected_categories))
        
        st.markdown("---")
        
        # å…³äº
        st.caption("**About**")
        st.caption("Cool Papers - Simplified Interface")
        st.caption("Data loaded from local JSON files")
    
    # ä¸»é¡µé¢
    st.header("arxiv è®ºæ–‡åŒæ­¥")

    st.markdown("---")

    # æ—¥æœŸå’Œåˆ†ç±»å¹¶æ’æ˜¾ç¤º
    date_col, cat_col = st.columns([1, 3])

    with date_col:
        st.caption("é€‰æ‹©æ—¥æœŸ")
        selected_date = st.date_input(
            "Select a date to view papers",
            value=datetime.now(),
            max_value=datetime.now(),
            min_value=datetime.now() - timedelta(days=365),
            key="date_picker",
            label_visibility="collapsed"
        )

    with cat_col:
        st.caption("ç±»åˆ«")
        if st.session_state.selected_categories:
            render_category_pills(st.session_state.selected_categories)
        else:
            st.warning("âš ï¸ Please select at least one category from the sidebar")

    date_str = selected_date.strftime("%Y-%m-%d")

    st.markdown("---")

    # æœç´¢åŒºåŸŸ - å•ç‹¬ä¸€è¡Œ
    st.header("æœç´¢")

    search_col1, search_col2, export_col = st.columns([4, 1, 1])
    with search_col1:
        search_query = st.text_input(
            "Search Query",
            placeholder="è¾“å…¥å…³é”®è¯ æˆ–è€… ä»€ä¹ˆéƒ½ä¸è¾“å…¥",
            label_visibility="collapsed",
            key="search_box"
        )

    with search_col2:
        search_button = st.button("Search", type="primary", use_container_width=True)

    # å¯¼å‡ºæŒ‰é’®ä¼šåœ¨è¿™é‡ŒåŠ¨æ€æ·»åŠ ï¼ˆå½“æœ‰è®ºæ–‡æ—¶ï¼‰
    
    st.markdown("---")
    
    # åŠ è½½å¹¶æ˜¾ç¤ºè®ºæ–‡
    if st.session_state.selected_categories:
        with st.spinner(f"Loading papers for {date_str}..."):
            # åŠ è½½è®ºæ–‡
            papers = load_papers_from_json(date_str, st.session_state.selected_categories)

            if not papers:
                st.warning(f"ğŸ“­ No papers found for date {date_str}")
            else:
                # è®ºæ–‡å·²ç»æŒ‰é€‰ä¸­çš„ç±»åˆ«åŠ è½½ï¼Œæ— éœ€é¢å¤–è¿‡æ»¤
                # ç¡®å®šè¦æ˜¾ç¤ºçš„è®ºæ–‡åˆ—è¡¨
                if search_query and search_query.strip():
                    # åœ¨åŠ è½½çš„è®ºæ–‡ä¸­æœç´¢
                    display_papers = search_papers(search_query, papers, st.session_state.selected_categories)

                    if not display_papers:
                        st.info(f"No results found for '{search_query}'")
                    else:
                        st.success(f"Found {len(display_papers)} papers matching '{search_query}'")
                else:
                    # æ˜¾ç¤ºæ€»åŠ è½½è®ºæ–‡æ•°é‡
                    st.success(f"âœ… Loaded {len(papers)} papers")
                    display_papers = papers

                # åœ¨æœç´¢åŒºåŸŸæ·»åŠ å¯¼å‡ºæŒ‰é’®
                if display_papers:
                    with export_col:
                        csv_data = papers_to_csv(display_papers)
                        # ä½¿ç”¨ç¨³å®šçš„keyï¼Œé¿å…åª’ä½“æ–‡ä»¶ç¼“å­˜å†²çª
                        download_key = f"download_csv_{date_str}"
                        st.download_button(
                            label="Export CSV",
                            data=csv_data,
                            file_name=f"papers_{date_str}.csv",
                            mime="text/csv",
                            key=download_key,
                            use_container_width=True
                        )

                # æ˜¾ç¤ºè®ºæ–‡åˆ—è¡¨
                for paper in display_papers:
                    render_paper_card(paper)
    
    # é¡µè„š
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666;">
        <p><strong>Cool Papers</strong> - Simplified Streamlit Interface</p>
        <p>Data loaded from local JSON files</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
